{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3BT3Q1lyxhLT",
        "outputId": "6a2202e5-0cb3-4872-bd97-6b42ed615ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipykernel in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (6.30.1)\n",
            "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (0.2.3)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (1.8.17)\n",
            "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (9.6.0)\n",
            "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (5.8.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging>=22 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (25.0)\n",
            "Requirement already satisfied: psutil>=5.7 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (7.1.0)\n",
            "Requirement already satisfied: pyzmq>=25 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (27.1.0)\n",
            "Requirement already satisfied: tornado>=6.2 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (6.5.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipykernel) (5.14.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
            "Requirement already satisfied: decorator in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
            "Requirement already satisfied: stack_data in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.4.0)\n",
            "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (311)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.5)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\"pippip\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (2.20.0)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (1.7.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (2.2.6)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (3.10.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (6.32.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (3.11.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
            "Requirement already satisfied: namex in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\desktop\\model_ai\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instalacion de dependecias del proyecto\n",
        "!pip install ipykernel\n",
        "!pippip install pydrive\n",
        "\n",
        "!pip install tensorflow opencv-python scikit-learn numpy matplotlib \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z6PKNdSa6op1"
      },
      "outputs": [],
      "source": [
        "# Define path data\n",
        "path_data = \"/gdrive/MyDrive/Bosco/garbage_dataset/garbage_classification/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAYjUNKH5ssK",
        "outputId": "bbfceaa8-c698-4d17-9c21-84a2f51fe2d5"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pydrive'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydrive\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleAuth\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydrive\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdrive\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleDrive\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Autenticación (esto abrirá tu navegador para iniciar sesión)\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pydrive'"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "\n",
        "# Autenticación (esto abrirá tu navegador para iniciar sesión)\n",
        "gauth = GoogleAuth()\n",
        "gauth.LocalWebserverAuth()\n",
        "\n",
        "# Crear cliente de Google Drive\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Listar archivos de tu Drive\n",
        "file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "for file in file_list:\n",
        "    print(f'Título: {file[\"title\"]} - ID: {file[\"id\"]}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiH0P2X892Ui"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def cargar_imagenes(dataset_path, map_categories, img_size=(224, 224)):\n",
        "\n",
        "    categorias = map_categories.keys()\n",
        "\n",
        "    imagenes = []\n",
        "    etiquetas = []\n",
        "\n",
        "    # Cargar imágenes por categoría\n",
        "    for idx, categoria in enumerate(categorias):\n",
        "      for garbage_type in map_categories[categoria]:\n",
        "        categoria_path = os.path.join(dataset_path, categoria, garbage_type) # Contruyo la ruta para llegar al path donde se almacenan las imagenes\n",
        "        for archivo in os.listdir(categoria_path): # Recorro las imagenes que hay en folder del garbage_type (Papel,plastico...)\n",
        "            if archivo.endswith('.jpg') or archivo.endswith('.png'):\n",
        "                img_path = os.path.join(categoria_path, archivo)\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.resize(img, img_size)  # Redimensionar a 224x224\n",
        "                img = img.astype('float32') / 255.0  # Normalizar a [0, 1]\n",
        "                imagenes.append(img)\n",
        "                etiquetas.append(idx)  # Etiquetar con el índice de la categoría\n",
        "\n",
        "    return np.array(imagenes), np.array(etiquetas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR50WaQVyUBt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "map_categories = {\n",
        "    \"APROVECHABLES\" : os.listdir(f\"{path_data}APROVECHABLES\"),\n",
        "    \"NO_APROVECHABLE\" : os.listdir(f\"{path_data}NO_APROVECHABLE\"),\n",
        "    \"ORGANICO\" : os.listdir(f\"{path_data}ORGANICO\")\n",
        "\n",
        "}\n",
        "\n",
        "# Cargar las imágenes y etiquetas\n",
        "imagenes, etiquetas = cargar_imagenes(path_data, map_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuyyxDvOIGvF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCFRwfa7-mRe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir en entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(imagenes, etiquetas, test_size=0.2, stratify=etiquetas)\n",
        "\n",
        "# Convertir las etiquetas a formato one-hot\n",
        "y_train = to_categorical(y_train, num_classes=3)\n",
        "y_val = to_categorical(y_val, num_classes=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NT4LnFODYyY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "def crear_modelo():\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Congelar las capas del modelo base\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),  # Capa de pooling global\n",
        "        Dropout(0.2),  # Para evitar sobreajuste\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(3, activation='softmax')  # Tres categorías\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Crear y entrenar el modelo\n",
        "modelo = crear_modelo()\n",
        "\n",
        "# Resumen del modelo\n",
        "modelo.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuwUmlmYEgL-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Usar early stopping para evitar sobreajuste\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Entrenar el modelo\n",
        "modelo.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfFSIVsWNCRT"
      },
      "outputs": [],
      "source": [
        "# Evaluacion del modelo en bajo nivel\n",
        "pérdida, precisión = modelo.evaluate(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRdy24KIMSjd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_val_indices = np.argmax(y_val, axis=1)\n",
        "\n",
        "# Hacemos predicciones\n",
        "y_pred = modelo.predict(X_val)\n",
        "y_pred_indices = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Crear matriz de confusión\n",
        "matriz_confusion = confusion_matrix(y_val_indices, y_pred_indices)\n",
        "\n",
        "# Nombres de las clases\n",
        "clases = map_categories.keys()\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=matriz_confusion, display_labels=clases)\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzC3MdjcNLkT"
      },
      "outputs": [],
      "source": [
        "def predecir_imagen(imagen_path):\n",
        "    img = cv2.imread(imagen_path) # <- Al integrar la camara me da directamente el objeto img, no necesito leer de un fichero\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = img.astype('float32') / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Expande la dimensión para que sea compatible con el modelo\n",
        "\n",
        "    prediccion = modelo.predict(img)\n",
        "    categoria_idx = np.argmax(prediccion, axis=1)\n",
        "    categorias = list(map_categories.keys())\n",
        "\n",
        "\n",
        "    print(f\"Predicción: {categorias[categoria_idx[0]]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0sAn87mNWOD"
      },
      "outputs": [],
      "source": [
        "path_image_test = \"/gdrive/MyDrive/Bosco/garbage_dataset/garbage_classification/cartyon.webp\" #    <-Aqui pongo la ruta de la iamgen que deseo evaluar\n",
        "\n",
        "# Ejemplo de predicción\n",
        "predecir_imagen(path_image_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXUzxnx5Ro_T"
      },
      "outputs": [],
      "source": [
        "modelo.save('/gdrive/MyDrive/Bosco/garbage_dataset/garbage_classification/modelo_mobilenetv2_entrenado.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.12.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
